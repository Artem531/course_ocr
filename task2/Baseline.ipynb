{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f37abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, ArchivedHWDBReader\n",
    "\n",
    "# your path to data\n",
    "train_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/train.zip'\n",
    "test_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/test.zip'\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042614e",
   "metadata": {},
   "source": [
    "# Simple CNN baseline\n",
    "\n",
    "pytorch is required for this baseline implementation\n",
    "\n",
    "## Baseline method\n",
    "\n",
    "- Naively resize to 32x32 (DON'T DO THIS IN YOUR WORK, try to save geometry somehow, it is important)\n",
    "- Train LeNet-like CNN\n",
    "- Enjoy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f84ab",
   "metadata": {},
   "source": [
    "### Data tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f882df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = ArchivedHWDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35cf8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92eb367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6636f",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42c7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.10.2)\n",
      "Requirement already satisfied: scikit-learn in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.0.2)\n",
      "Requirement already satisfied: torchvision in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (0.11.3)\n",
      "Requirement already satisfied: numpy in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (4.62.3)\n",
      "Requirement already satisfied: typing_extensions in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.10.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from torchvision->pytorch-metric-learning) (8.4.0)\n",
      "Requirement already satisfied: umap-learn in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (0.5.3)\n",
      "Requirement already satisfied: tqdm in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (4.62.3)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (0.5.6)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.7.3)\n",
      "Requirement already satisfied: numba>=0.49 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (0.55.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.21.2)\n",
      "Requirement already satisfied: setuptools in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (0.38.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f5d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): MobileNetV3(\n",
      "    (features): Sequential(\n",
      "      (0): ConvNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): ConvNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "      (1): Hardswish()\n",
      "      (2): Dropout(p=0.2, inplace=True)\n",
      "      (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(models.mobilenet_v3_large(pretrained=True),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1000, 1000))\n",
    "                      \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d0540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def run_validation(val_loader: DataLoader, model: nn.Module, n_steps=None, loss_fn=None):\n",
    "    model.eval()\n",
    "    n_good = 0\n",
    "    n_all = 0\n",
    "    wrapper = lambda x: x\n",
    "    if n_steps is None:\n",
    "        n_steps = len(val_loader)\n",
    "        wrapper = tqdm\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(wrapper(val_loader)):\n",
    "            if batch == n_steps:\n",
    "                break\n",
    "            embeddings = model(X.to(torch.float32).cuda())\n",
    "            logits = loss_fn.get_logits(embeddings)\n",
    "\n",
    "            classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            n_good += sum(classes == y.cpu().numpy())\n",
    "            n_all += len(classes)\n",
    "    \n",
    "    return n_good / n_all\n",
    "\n",
    "def train_epoch(train_loader: DataLoader, val_loader: DataLoader, model: nn.Module, optim, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(tqdm(train_loader)):\n",
    "        features = model( X.to(torch.float32).cuda() )      \n",
    "        loss = loss_fn(features, y.to(torch.long).cuda()) \n",
    "\n",
    "        optim[0].zero_grad()\n",
    "        optim[1].zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optim[0].step()\n",
    "        optim[1].step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7909cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHWDBDataset(Dataset):\n",
    "    def __init__(self, helper: HWDBDatasetHelper):\n",
    "        self.helper = helper\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.helper.size()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.helper.get_item(idx)\n",
    "        hi, wi = img.shape\n",
    "        \n",
    "        # Уменьшаем размер картинки до 64 с минимальными рамками\n",
    "        size = 64\n",
    "        maxCurSize = max(wi, hi)\n",
    "        ratio = maxCurSize / size    \n",
    "        wi, hi = int(wi / ratio), int(hi / ratio) \n",
    "        img = cv2.resize(img, (wi, hi))\n",
    "\n",
    "        frame = np.zeros((size, size)) + 255\n",
    "        \n",
    "        h, w = img.shape\n",
    "        \n",
    "        frame[:h, :w] = img.copy()\n",
    "        frame = frame.astype(np.uint8)\n",
    "        im_rgb = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "        im_rgb = np.swapaxes(im_rgb,0,2)\n",
    "        im_rgb = np.swapaxes(im_rgb,1,2)\n",
    "        return (im_rgb - 127.5) / 255., label    \n",
    "    \n",
    "\n",
    "train_dataset = MyHWDBDataset(train_helper)\n",
    "val_dataset = MyHWDBDataset(val_helper)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66824a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses\n",
    "import torch\n",
    "\n",
    "loss_emb = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1000).to(torch.device('cuda'))\n",
    "loss_optimizer = torch.optim.Adam(loss_emb.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = loss_emb\n",
    "optim = [torch.optim.Adam(model.parameters(), lr=1e-3), loss_optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cea0197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_dataset[0][0][0])\n",
    "plt.show()\n",
    "#print(train_dataset[0][0].shape)\n",
    "#model(torch.tensor(train_dataset[0][0], dtype=torch.float32).unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eaeaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1ef533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2518/2518 [31:07<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [05:19<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8404164384921712\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2518/2518 [30:44<00:00,  1.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [05:15<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8957600654039891\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2518/2518 [30:24<00:00,  1.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [05:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9199576797717687\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2518/2518 [30:26<00:00,  1.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [05:30<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9244627363254314\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2518/2518 [30:31<00:00,  1.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [05:16<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9240780069778735\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f'Epoch {epoch}:')\n",
    "    train_epoch(train_loader, val_loader, model, optim, loss_fn)\n",
    "    accuracy = run_validation(val_loader, model, loss_fn=loss_fn)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    torch.save(model.state_dict(), f'baseline_epoch{epoch}.pth')\n",
    "    torch.save(loss_fn.state_dict(), f'loss{epoch}.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7d2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'baseline.pth')\n",
    "torch.save(loss_fn.state_dict(), f'loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "084adbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/test.zip'\n",
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = ArchivedHWDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c51b0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyHWDBDataset(test_helper)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b84f75d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 380/380 [04:08<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "\n",
    "loss_fn = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1000).to(torch.device('cuda'))\n",
    "PATH = \"/home/artem/PycharmProjects/course_ocr/course_ocr/task2/loss.pth\"\n",
    "loss_fn.load_state_dict(torch.load(PATH))\n",
    "loss_fn.eval().cuda()\n",
    "\n",
    "model = nn.Sequential(models.mobilenet_v3_large(pretrained=True),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1000, 1000))\n",
    "PATH = \"/home/artem/PycharmProjects/course_ocr/course_ocr/task2/baseline.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        embeddings = model(X.to(torch.float32).cuda())\n",
    "        logits = loss_fn.get_logits(embeddings)\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce079c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c2491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9053\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def evaluate(gt_path, pred_path):\n",
    "    gt = dict()\n",
    "    with open(gt_path) as gt_f:\n",
    "        for line in gt_f:\n",
    "            name, cls = line.strip().split()\n",
    "            gt[name] = cls\n",
    "    \n",
    "    n_good = 0\n",
    "    n_all = len(gt)\n",
    "    with open(pred_path) as pred_f:\n",
    "        for line in pred_f:\n",
    "            name, cls = line.strip().split()\n",
    "            if cls == gt[name]:\n",
    "                n_good += 1\n",
    "    \n",
    "    return n_good / n_all\n",
    "\n",
    "\n",
    "def _run_evaluation():\n",
    "    base = Path(\"/home/artem/PycharmProjects/course_ocr/course_ocr/task2\")\n",
    "    gt_path = base / 'gt.txt'\n",
    "    pred_path = base / 'pred.txt'\n",
    "    score = evaluate(gt_path, pred_path)\n",
    "    print('Accuracy = {:1.4f}'.format(score))\n",
    "\n",
    "_run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a3fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
