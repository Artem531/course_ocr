{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f37abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, ArchivedHWDBReader\n",
    "\n",
    "# your path to data\n",
    "train_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/train.zip'\n",
    "test_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/test.zip'\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042614e",
   "metadata": {},
   "source": [
    "# Simple CNN baseline\n",
    "\n",
    "pytorch is required for this baseline implementation\n",
    "\n",
    "## Baseline method\n",
    "\n",
    "- Naively resize to 32x32 (DON'T DO THIS IN YOUR WORK, try to save geometry somehow, it is important)\n",
    "- Train LeNet-like CNN\n",
    "- Enjoy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f84ab",
   "metadata": {},
   "source": [
    "### Data tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f882df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = ArchivedHWDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35cf8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92eb367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6636f",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42c7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.0.2)\n",
      "Requirement already satisfied: tqdm in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (4.62.3)\n",
      "Requirement already satisfied: numpy in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.21.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (1.10.2)\n",
      "Requirement already satisfied: torchvision in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pytorch-metric-learning) (0.11.3)\n",
      "Requirement already satisfied: typing_extensions in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.10.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from torchvision->pytorch-metric-learning) (8.4.0)\n",
      "Requirement already satisfied: umap-learn in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (4.62.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.7.3)\n",
      "Requirement already satisfied: numba>=0.49 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (0.55.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (1.0.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from umap-learn) (0.5.6)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (58.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/artem/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f5d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "                      \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d0540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def run_validation(val_loader: DataLoader, model: nn.Module, n_steps=None):\n",
    "    model.eval()\n",
    "    n_good = 0\n",
    "    n_all = 0\n",
    "    wrapper = lambda x: x\n",
    "    if n_steps is None:\n",
    "        n_steps = len(val_loader)\n",
    "        wrapper = tqdm\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(wrapper(val_loader)):\n",
    "            if batch == n_steps:\n",
    "                break\n",
    "            _, probs = model(X.unsqueeze(1).to(torch.float32).cuda())\n",
    "            classes = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "            n_good += sum(classes == y.cpu().numpy())\n",
    "            n_all += len(classes)\n",
    "    \n",
    "    return n_good / n_all\n",
    "\n",
    "def train_epoch(train_loader: DataLoader, val_loader: DataLoader, model: nn.Module, optim, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(tqdm(train_loader)):\n",
    "                \n",
    "        features = model( X.to(torch.float32).cuda() )      \n",
    "        loss = loss_fn(features, y.to(torch.long).cuda()) \n",
    "\n",
    "        optim[0].zero_grad()\n",
    "        optim[1].zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optim[0].step()\n",
    "        optim[1].step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7909cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyHWDBDataset(Dataset):\n",
    "    def __init__(self, helper: HWDBDatasetHelper):\n",
    "        self.helper = helper\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.helper.size()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.helper.get_item(idx)\n",
    "        hi, wi = img.shape\n",
    "        \n",
    "        size = 64\n",
    "        while hi < size and wi < size:\n",
    "            hi = hi * 2\n",
    "            wi = wi * 2\n",
    "        \n",
    "        while hi > size or wi > size:\n",
    "            hi = hi // 2\n",
    "            wi = wi // 2\n",
    "            \n",
    "        img = cv2.resize(img, (wi, hi))\n",
    "\n",
    "        frame = np.zeros((3, size, size)) + 255\n",
    "        \n",
    "        h, w = img.shape\n",
    "        \n",
    "        frame[0, :h, :w] = img.copy()\n",
    "        frame[1, :h, :w] = img.copy()\n",
    "        frame[2, :h, :w] = img.copy()\n",
    "        \n",
    "        return (frame - 127.5) / 255., label\n",
    "\n",
    "train_dataset = MyHWDBDataset(train_helper)\n",
    "val_dataset = MyHWDBDataset(val_helper)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66824a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses\n",
    "import torch\n",
    "\n",
    "loss_emb = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1000).to(torch.device('cuda'))\n",
    "loss_optimizer = torch.optim.Adam(loss_emb.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = loss_emb\n",
    "optim = [torch.optim.Adam(model.parameters(), lr=1e-3), loss_optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cea0197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_dataset[0][0][0])\n",
    "plt.show()\n",
    "#print(train_dataset[0][0].shape)\n",
    "#model(torch.tensor(train_dataset[0][0], dtype=torch.float32).unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eaeaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1ef533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 1667/2518 [15:23<07:51,  1.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4259/27909163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'accuracy: {accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4259/3311549326.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, val_loader, model, optim, loss_fn)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CenterNetRefs/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4259/479983243.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/course_ocr/course_ocr/task2/data_reader.py\u001b[0m in \u001b[0;36mget_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_by_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHWDBDatasetHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/course_ocr/course_ocr/task2/data_reader.py\u001b[0m in \u001b[0;36mdecode_image\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(1):\n",
    "    print(f'Epoch {epoch}:')\n",
    "    train_epoch(train_loader, val_loader, model, optim, loss_fn)\n",
    "    accuracy = run_validation(val_loader, model)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    torch.save(model.state_dict(), f'baseline_epoch{epoch}.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea0c7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(loss_fn.state_dict(), f'loss0.pth')\n",
    "torch.save(model.state_dict(), f'baseline_epoch0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084adbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'/media/artem/A2F4DEB0F4DE85C7/myData/datasets/HWDBT/test.zip'\n",
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = ArchivedHWDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51b0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyHWDBDataset(test_helper)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b84f75d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 380/380 [03:21<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "\n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "PATH = \"/home/artem/PycharmProjects/course_ocr/course_ocr/task2/baseline_epoch0.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval().cuda()\n",
    "\n",
    "loss_fn = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1000).to(torch.device('cuda'))\n",
    "PATH = \"/home/artem/PycharmProjects/course_ocr/course_ocr/task2/loss0.pth\"\n",
    "loss_fn.load_state_dict(torch.load(PATH))\n",
    "loss_fn.eval().cuda()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        \n",
    "        embeddings = model(X.to(torch.float32).cuda())\n",
    "        logits = loss_fn.get_logits(embeddings)\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce079c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c2491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.2872\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def evaluate(gt_path, pred_path):\n",
    "    gt = dict()\n",
    "    with open(gt_path) as gt_f:\n",
    "        for line in gt_f:\n",
    "            name, cls = line.strip().split()\n",
    "            gt[name] = cls\n",
    "    \n",
    "    n_good = 0\n",
    "    n_all = len(gt)\n",
    "    with open(pred_path) as pred_f:\n",
    "        for line in pred_f:\n",
    "            name, cls = line.strip().split()\n",
    "            if cls == gt[name]:\n",
    "                n_good += 1\n",
    "    \n",
    "    return n_good / n_all\n",
    "\n",
    "\n",
    "def _run_evaluation():\n",
    "    base = Path(\"/home/artem/PycharmProjects/course_ocr/course_ocr/task2\")\n",
    "    gt_path = base / 'gt.txt'\n",
    "    pred_path = base / 'pred.txt'\n",
    "    score = evaluate(gt_path, pred_path)\n",
    "    print('Accuracy = {:1.4f}'.format(score))\n",
    "\n",
    "_run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a3fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
