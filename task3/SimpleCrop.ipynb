{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d133d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models                      \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import segmentation_models_pytorch\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\n",
    "    'cpu')  # Check if there is GPU if not set trainning to CPU (very slow)\n",
    "\n",
    "\n",
    "modelPath = \"4000.torch\"\n",
    "width, height = 256, 256  # image width and height\n",
    "\n",
    "Learning_Rate=1e-5\n",
    "batchSize=16\n",
    "\n",
    "transformImg = tf.Compose([tf.Resize((height, width)), tf.ToTensor(), tf.Normalize((0.485, 0.456, 0.406),\n",
    "                                                                                   (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "data_paths_images = Path(\"/media/artem/A2F4DEB0F4DE85C7/myData/datasets/barcodes_hw/Test-20220427T080744Z-001/Test/Images\")\n",
    "\n",
    "onlyfiles_paths_images = {f: join(data_paths_images, f) for f in listdir(data_paths_images) if isfile(join(data_paths_images, f))}\n",
    "\n",
    "seg_model = segmentation_models_pytorch.UnetPlusPlus(in_channels=3, classes=1)\n",
    "seg_model.load_state_dict(torch.load(modelPath))\n",
    "seg_model.to(device).eval()\n",
    "\n",
    "def getSubImage(best_area, src):\n",
    "    # Get center, size, and angle from rect\n",
    "    pts1 = np.float32(best_area)\n",
    "    pts2 = np.float32([[300, 300], [0, 300], [0, 0], [300, 0]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    out = cv2.warpPerspective(src, M, (300, 300))\n",
    "\n",
    "    img90 = np.rot90(out)\n",
    "    img180 = np.rot90(img90)\n",
    "    img_n270 = np.rot90(img180)\n",
    "    img = out\n",
    "\n",
    "    return img, img90, img180, img_n270\n",
    "\n",
    "def cutBarcode(x):\n",
    "    width_orgin, height_orgin = x.size[0], x.size[1]  # Get image original size\n",
    "\n",
    "    Img = transformImg(x)  # Transform to pytorch\n",
    "    Img = torch.autograd.Variable(Img, requires_grad=False).to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Prd = seg_model(Img) \n",
    "\n",
    "    Prd = tf.Resize((height_orgin, width_orgin))(Prd[0])[0]  # Resize to origninal size\n",
    "\n",
    "    mask = Prd.detach().cpu().numpy() > 0.5\n",
    "    mask_img = mask.astype(np.uint8)\n",
    "\n",
    "    w, h = mask_img.shape\n",
    "\n",
    "    mask_img *= 255\n",
    "    \n",
    "    Img_orig = x\n",
    "    contours, _ = cv2.findContours(mask_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    best_area = []\n",
    "    max_S = -1\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > max_S:\n",
    "            epsilon = 0.1*cv2.arcLength(cnt,True)\n",
    "\n",
    "            \n",
    "            tmp_area = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "            if len(tmp_area) == 4:\n",
    "                best_area = tmp_area\n",
    "                max_S = area\n",
    "   \n",
    "    if len(best_area) != 4:\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > max_S:\n",
    "                epsilon = 0.1*cv2.arcLength(cnt,True)\n",
    "\n",
    "                tmp_area = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "                best_area = []\n",
    "                \n",
    "                best_area.append(tmp_area[0])\n",
    "                best_area.append([[tmp_area[0][0][0], tmp_area[1][0][1]]])\n",
    "                best_area.append(tmp_area[1])\n",
    "                best_area.append([[tmp_area[1][0][0], tmp_area[0][0][1]]])\n",
    "                max_S = area\n",
    "    \n",
    "    #Img_orig = np.array(Img_orig)\n",
    "    #barcodes = getSubImage(best_area, Img_orig)[0]\n",
    "    \n",
    "    #plt.imshow(barcodes)  # display image\n",
    "    #plt.show()\n",
    "    \n",
    "    return best_area\n",
    "\n",
    "def getCords(onlyfiles_paths_images, name):  # First lets load random image and  the corresponding annotation    \n",
    "    img_file_path =  onlyfiles_paths_images[name]\n",
    "    \n",
    "    crop_cords =  cutBarcode(Image.open(img_file_path, mode='r', formats=None))\n",
    "    return crop_cords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf61073",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f9bf5d96a0cf5d64aac4eb5806554224.png\n",
      "a154b624c06072da1a01c97ebc3894c1.png\n",
      "749003091876fc58be69db54bbaae8f1.png\n",
      "560ca4ac1260313eb5979140c4f9ef31.png\n",
      "2bc877416a54aea8a94227ce9d1e5d1f.png\n",
      "589b454c920322816d8df0494cb07bba.png\n",
      "cd82f250fa1ff45ae2eada5d91ed90a2.png\n",
      "2ebb873b5b1a0c782e8432cf3a82d71f.png\n",
      "36824964d90c9e9ebc65eeb1b0438c66.png\n",
      "365df19a3155c1019ea182329a074f47.png\n",
      "c3c5e1e6da39334c32873c0cf4eeb9ec.png\n",
      "54c516c07afe31075266f04a04d2d03a.png\n",
      "7ba840fa58126ec78764d77ee9720a27.png\n",
      "fedcc45b69bb6c40c4599bbb499ee365.png\n",
      "6c0923f882043d8ab709537da2813042.png\n",
      "aab7bd3438de5ce40c4c7de3db0ecf23.png\n",
      "7711af7efa618bf29db3e2ad72ee534a.png\n",
      "d0581f8681b200dc78ef271460905612.png\n",
      "40ed826ebe0916f70999c831fc078faf.png\n",
      "1cd72c7dcf77e1b8a401c0a7b41573c8.png\n",
      "632cf29db1b4cfb252d20edba6508639.png\n",
      "eddb324b906534e158177f022a1ca3b4.png\n",
      "f7c811258e32c7150ff454bf419e8bc7.png\n",
      "2de6d574d39d2c8fcb700ab62fa25e94.png\n",
      "099574d0f797fe2519686fd1e724ebf3.png\n",
      "429394b77b7a164916bbf2a8a824f30e.png\n",
      "a6522bc3e9d7207451c564c3bb4a89b8.png\n",
      "8119f75cd210f514dda33eab7d64b9d6.png\n",
      "157a4b17084b43ef3b572dd7267e76d0.png\n",
      "d0adf4fa6ec14c14d53e210a9a279e75.png\n",
      "ad33d4cb49ac5a476768dd96b6eed78e.png\n",
      "88cb4b415dac218527ecc74dc6df522c.png\n",
      "aa43c03597169dc7c6b5c41c47f7e0ad.png\n",
      "97376e1b07bd92b927f4e8508fda19a2.png\n",
      "8119dd3a93dbf4e27cc3ba7262bd311e.png\n",
      "e7eb0c61166a35f7be5885481a3ea822.png\n",
      "bd977af95e836c9dee8918e024f6ac9f.png\n",
      "4391a02a103037aa5b77e676f48213d8.png\n",
      "5b972b1719a7b56b69cfecaf7030705f.png\n",
      "065c4a67725752b09302b0a6a5ad3971.png\n",
      "5bff157e9089eae875de1eb057e4ab27.png\n",
      "6cda80c14779289c3a3afcea4ef8f880.png\n",
      "58a2f243e9fdebb829c9aa954c1ced6a.png\n",
      "4de809d33c56a83ae75f4ed10a027998.png\n",
      "3c2daadda4f2cea3924df756aa363ec7.png\n",
      "941206fe88e2034b2f9e1f6ffc90070a.png\n",
      "cdace7e42905482180185afe7d8d3fa0.png\n",
      "10c9065a00b9bea9b741208b2679cf76.png\n",
      "c1fa89750734038a460cd1ca25e595e6.png\n",
      "e7979371f1f2b49b63b33d625e51d2d5.png\n",
      "b6a7f81f78800c77b3c27b45531ee0c4.png\n",
      "16cd16966b3339632b8dbce36225237c.png\n",
      "c8d3c60c36581b2edab0bb647e48f694.png\n",
      "f3ff64553032c54e8f603cdf68600adf.png\n",
      "ca5bb0eddd893fb4b0e5ffa8f351412e.png\n",
      "021e9179bdd3287d873de5208535b4a7.png\n",
      "a417bfe1b2ea0e2ac15c92db789ff500.png\n",
      "36218303d390a25f042fb9844133e911.png\n",
      "afd709c701704672c18db8d2684e0ae6.png\n",
      "1b40467bc7b1623a8c957719fcf61b54.png\n",
      "19b01a2c6deeda40dbbdc6c54b7b6497.png\n",
      "cc05f96fd5e98ca1243693586aacba88.png\n",
      "5e6e9e51d51b1f0a0eb5815e009200af.png\n",
      "698e5fd96d25b1cc96b5711091172345.png\n",
      "48e4ee3749f5e786d2160d5081a4640f.png\n",
      "b1ed0a3f257cf01212f4285dadd38f21.png\n",
      "f2ce1cdeaeb9992376a475c51fda2b7b.png\n",
      "96e66885affdc2a79ac0789318a3d530.png\n",
      "3611f7a3a6cdd3dac9979517b736cf6a.png\n",
      "dc706a5a1d6f8987b93bca7c2e737746.png\n",
      "bd73209510e733ac86f830442074385a.png\n",
      "2927ce6ceccad5fab23e5b332894c5e1.png\n",
      "e083bf4d3c80b00698abdf7b4e769a8c.png\n",
      "710eb9174efd4f943aa75c79e89a5bdc.png\n",
      "e8c43ae814911c4622987809d4850336.png\n",
      "37de452d05e9ecbed02a3966a1fa71b2.png\n",
      "a6e233ce71def579f34570953163d255.png\n",
      "b9a2dedf327a793702b3c1ccad171dea.png\n",
      "d28f09879d22495e4ec234a5287a6c30.png\n",
      "1105913212699e2e8a558191113acbd7.png\n",
      "c683d3627b6766ef1acd6efd52316be8.png\n",
      "ffe23e3a864dd809237d289e81083a0d.png\n",
      "9f627a286049886c0f3232a2469b3cc9.png\n",
      "ab30ca615e3fb75d5bcbf0b1aa663f69.png\n",
      "99a0962609cf1f72e6990b0d1c8cf3fe.png\n",
      "00f3d3d8b60ef559304ff51cadaf4fb1.png\n",
      "c5593983feae425b9a2117279450d5d4.png\n",
      "a7f9f2ac26ac6d10009611e290adb470.png\n",
      "e5a9138a94f2ed782a77f2ef4b0a5e24.png\n",
      "7e56f424b1cd4515c744543907e89663.png\n",
      "4e19d13913850c634fa6ca54850b6914.png\n",
      "144b3c6678312a8dddaaa713c9f56a71.png\n",
      "e5aa00f9b8978a02f20e4ca017bb6d80.png\n",
      "97b2e27686dbb54b20cfbf9696d430f1.png\n",
      "bf547f52301ee51df5faf1a6dc678740.png\n",
      "d7d7c5f9109aa31aff407eeab054bfc7.png\n",
      "d6230eb6dc78728c09024eb674c427ef.png\n",
      "f534d421c7e36d6133a5e9031a7e2dd5.png\n",
      "2e83c9d27bbdb98505c76a19f19cb9d7.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame = pd.read_csv(\"/home/artem/PycharmProjects/course_ocr/course_ocr/task3/ref_answer.csv\", encoding=\"utf-16\")\n",
    "\n",
    "ans = []\n",
    "\n",
    "for idx, row in dataFrame.iterrows(): # Training loop\n",
    "    name = row[0]\n",
    "    row = []\n",
    "    print(name)\n",
    "    cords = getCords(onlyfiles_paths_images, name)\n",
    "    row.append(name)\n",
    "    row.append(\"0000000000000\")\n",
    "    \n",
    "    row.append(str(int(cords[0][0][0])))\n",
    "    row.append(str(int(cords[0][0][1])))\n",
    "    \n",
    "    \n",
    "    row.append(str(int(cords[1][0][0])))\n",
    "    row.append(str(int(cords[1][0][1])))\n",
    "    \n",
    "    row.append(str(int(cords[2][0][0])))\n",
    "    row.append(str(int(cords[2][0][1])))\n",
    "    \n",
    "    row.append(str(int(cords[3][0][0])))\n",
    "    row.append(str(int(cords[3][0][1])))\n",
    "    \n",
    "    row.append(\"1111111111111111111111111111111111111111111111111\")\n",
    "    ans.append(row)\n",
    "\n",
    "ans_csv = pd.DataFrame(ans)\n",
    "\n",
    "ans_csv.to_csv(\"/home/artem/PycharmProjects/course_ocr/course_ocr/task3/answer.csv\", header=False, encoding=\"utf-16\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc279152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f8bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
